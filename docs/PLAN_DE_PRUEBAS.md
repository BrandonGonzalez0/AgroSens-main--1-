# Plan de Pruebas - AgroSens

## üìã Informaci√≥n del Documento

**Proyecto:** AgroSens - Sistema de Monitoreo Agr√≠cola Inteligente  
**Versi√≥n:** 1.0  
**Fecha:** Noviembre 2025  
**Responsable:** Equipo de Desarrollo AgroSens

---

## 1. Introducci√≥n

### 1.1 Prop√≥sito
Este documento establece el plan de pruebas integral para el sistema AgroSens, definiendo estrategias, tipos de pruebas, recursos necesarios y criterios de aceptaci√≥n para garantizar la calidad del software.

### 1.2 Alcance
El plan cubre todas las funcionalidades del sistema AgroSens:
- Backend (API REST en Node.js/Express)
- Frontend (React con Vite)
- Sistema de Machine Learning (TensorFlow)
- Integraci√≥n con sensores IoT
- Seguridad y protecci√≥n de datos
- Rendimiento y escalabilidad

### 1.3 Objetivos
- Validar funcionalidad completa del sistema
- Garantizar seguridad y protecci√≥n contra vulnerabilidades
- Verificar rendimiento bajo carga
- Asegurar compatibilidad cross-browser y dispositivos
- Confirmar precisi√≥n del modelo de IA
- Validar integridad de datos

---

## 2. Estrategia de Pruebas

### 2.1 Niveles de Pruebas

#### **Pruebas Unitarias**
- **Cobertura objetivo:** ‚â• 70%
- **Herramientas:** Jest, Mocha, PyTest
- **Responsable:** Desarrolladores
- **Frecuencia:** Continua (cada commit)

#### **Pruebas de Integraci√≥n**
- **Cobertura objetivo:** ‚â• 60%
- **Herramientas:** Supertest, Jest
- **Responsable:** Equipo QA + Desarrolladores
- **Frecuencia:** Diaria (builds nocturnos)

#### **Pruebas de Sistema**
- **Cobertura objetivo:** 100% casos de uso cr√≠ticos
- **Herramientas:** Cypress, Playwright
- **Responsable:** Equipo QA
- **Frecuencia:** Semanal + Pre-release

#### **Pruebas de Aceptaci√≥n**
- **Cobertura objetivo:** 100% requisitos funcionales
- **Herramientas:** Pruebas manuales guiadas
- **Responsable:** Product Owner + Usuarios finales
- **Frecuencia:** Cada sprint + Pre-release

---

## 3. Tipos de Pruebas

### 3.1 Pruebas Funcionales

#### **M√≥dulo: Gesti√≥n de Cultivos**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-001 | Crear nuevo cultivo | Alta | - |
| TC-002 | Editar cultivo existente | Alta | - |
| TC-003 | Eliminar cultivo | Media | - |
| TC-004 | Buscar cultivos por filtros | Media | - |
| TC-005 | Visualizar historial de cultivo | Alta | - |

#### **M√≥dulo: Sensores IoT**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-006 | Recibir lectura de sensor (pH) | Cr√≠tica | - |
| TC-007 | Recibir lectura de sensor (humedad) | Cr√≠tica | - |
| TC-008 | Recibir lectura de sensor (temperatura) | Cr√≠tica | - |
| TC-009 | Validar rango de datos de sensor | Alta | - |
| TC-010 | Almacenar datos de telemetr√≠a | Alta | - |
| TC-011 | Recuperar √∫ltima lectura | Alta | - |

#### **M√≥dulo: An√°lisis con IA**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-012 | Subir imagen para an√°lisis | Cr√≠tica | - |
| TC-013 | Clasificar enfermedad de planta | Cr√≠tica | - |
| TC-014 | Generar recomendaciones | Alta | - |
| TC-015 | Validar formato de imagen | Alta | - |
| TC-016 | Manejo de imagen corrupta | Media | - |
| TC-017 | Precisi√≥n del modelo (‚â•85%) | Cr√≠tica | - |

#### **M√≥dulo: Alertas**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-018 | Generar alerta por valor cr√≠tico | Cr√≠tica | - |
| TC-019 | Notificar usuario de alerta | Alta | - |
| TC-020 | Marcar alerta como le√≠da | Media | - |
| TC-021 | Filtrar alertas por tipo | Media | - |

#### **M√≥dulo: Clima**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-022 | Obtener datos meteorol√≥gicos | Alta | - |
| TC-023 | Validar coordenadas GPS | Alta | - |
| TC-024 | Manejo de API externa ca√≠da | Media | - |
| TC-025 | Cache de datos meteorol√≥gicos | Baja | - |

#### **M√≥dulo: Usuarios**
| ID | Caso de Prueba | Prioridad | Estado |
|----|----------------|-----------|--------|
| TC-026 | Registrar nuevo usuario | Alta | - |
| TC-027 | Iniciar sesi√≥n | Cr√≠tica | - |
| TC-028 | Cerrar sesi√≥n | Media | - |
| TC-029 | Recuperar contrase√±a | Media | - |
| TC-030 | Actualizar perfil de usuario | Baja | - |

---

### 3.2 Pruebas de Seguridad

#### **Vulnerabilidades OWASP Top 10**
| ID | Prueba de Seguridad | Severidad | M√©todo |
|----|---------------------|-----------|--------|
| TS-001 | Inyecci√≥n SQL/NoSQL | Cr√≠tica | Prueba automatizada + Manual |
| TS-002 | Cross-Site Scripting (XSS) | Cr√≠tica | Prueba automatizada |
| TS-003 | Cross-Site Request Forgery (CSRF) | Alta | Validaci√≥n de tokens |
| TS-004 | Exposici√≥n de datos sensibles | Cr√≠tica | Auditor√≠a de logs y respuestas |
| TS-005 | Control de acceso roto | Alta | Pruebas de autorizaci√≥n |
| TS-006 | Configuraci√≥n incorrecta | Media | Revisi√≥n de configuraci√≥n |
| TS-007 | Deserializaci√≥n insegura | Media | An√°lisis de payloads |
| TS-008 | Componentes vulnerables | Alta | Escaneo de dependencias |
| TS-009 | Registro y monitoreo insuficiente | Baja | Revisi√≥n de logs |
| TS-010 | Server-Side Request Forgery (SSRF) | Alta | Validaci√≥n de URLs externas |

#### **Pruebas de Autenticaci√≥n y Autorizaci√≥n**
| ID | Caso de Prueba | Criterio de Aceptaci√≥n |
|----|----------------|------------------------|
| TS-011 | Fuerza bruta de contrase√±as | Rate limiting bloquea despu√©s de 5 intentos |
| TS-012 | Sesiones concurrentes | L√≠mite configurable por usuario |
| TS-013 | Timeout de sesi√≥n | Sesi√≥n expira despu√©s de 24h de inactividad |
| TS-014 | Token CSRF v√°lido | Rechazo de peticiones sin token v√°lido |
| TS-015 | Headers de seguridad | Todos los headers requeridos presentes |

#### **Pruebas de Entrada de Datos**
| ID | Caso de Prueba | Vector de Ataque |
|----|----------------|------------------|
| TS-016 | Validaci√≥n de pH | Valores fuera de rango 0-14 |
| TS-017 | Validaci√≥n de humedad | Valores fuera de rango 0-100% |
| TS-018 | Validaci√≥n de temperatura | Valores fuera de rango -50 a 100¬∞C |
| TS-019 | Path Traversal en uploads | `../../../etc/passwd` |
| TS-020 | Polyglot file upload | Archivo con m√∫ltiples extensiones |

#### **Script de Pruebas Automatizadas**
- **Herramienta:** `test-security.ps1` (PowerShell) / `test-security.sh` (Bash)
- **Ejecuci√≥n:** `.\test-security.ps1`
- **Cobertura:** 10 categor√≠as de seguridad
- **Criterio de √©xito:** ‚â• 80% PASS

---

### 3.3 Pruebas de Rendimiento

#### **Pruebas de Carga**
| Escenario | Usuarios Concurrentes | Duraci√≥n | M√©trica Objetivo |
|-----------|----------------------|----------|------------------|
| Lectura de sensores | 100 | 10 min | Latencia p95 < 200ms |
| An√°lisis de IA | 20 | 5 min | Latencia p95 < 3s |
| Consulta de cultivos | 200 | 15 min | Latencia p95 < 150ms |
| API meteorol√≥gica | 50 | 10 min | Latencia p95 < 500ms |

#### **Pruebas de Estr√©s**
- **Objetivo:** Determinar punto de quiebre del sistema
- **M√©todo:** Incremento gradual de usuarios hasta fallo
- **Herramientas:** Apache JMeter, k6
- **Criterio:** Sistema debe degradarse gracefully

#### **Pruebas de Estabilidad**
- **Duraci√≥n:** 24 horas continuas
- **Carga:** 50% de capacidad m√°xima
- **Objetivo:** Sin memory leaks, conexiones abiertas o degradaci√≥n

#### **Pruebas de Picos**
- **Patr√≥n:** Carga normal ‚Üí Pico 10x ‚Üí Carga normal
- **Duraci√≥n del pico:** 2 minutos
- **Criterio:** Recuperaci√≥n < 5 minutos

---

### 3.4 Pruebas de Compatibilidad

#### **Navegadores Web**
| Navegador | Versi√≥n | Desktop | Mobile | Estado |
|-----------|---------|---------|--------|--------|
| Chrome | Latest | ‚úì | ‚úì | - |
| Firefox | Latest | ‚úì | ‚úì | - |
| Safari | Latest | ‚úì | ‚úì | - |
| Edge | Latest | ‚úì | - | - |

#### **Dispositivos M√≥viles**
| Dispositivo | OS | Resoluci√≥n | Estado |
|-------------|----|-----------:|--------|
| iPhone 12+ | iOS 15+ | 390x844 | - |
| Samsung Galaxy | Android 11+ | 360x800 | - |
| iPad | iOS 15+ | 768x1024 | - |

#### **Resoluciones de Pantalla**
- Mobile: 360x640, 375x667, 414x896
- Tablet: 768x1024, 820x1180
- Desktop: 1366x768, 1920x1080, 2560x1440

---

### 3.5 Pruebas de Machine Learning

#### **Validaci√≥n del Modelo**
| M√©trica | Objetivo | M√©todo de Medici√≥n |
|---------|----------|--------------------|
| Accuracy | ‚â• 85% | Dataset de validaci√≥n |
| Precisi√≥n | ‚â• 80% | Por clase de enfermedad |
| Recall | ‚â• 80% | Por clase de enfermedad |
| F1-Score | ‚â• 80% | Promedio ponderado |
| Inference Time | < 2s | Imagen 224x224 |

#### **Casos de Prueba de IA**
| ID | Caso de Prueba | Dataset | Resultado Esperado |
|----|----------------|---------|-------------------|
| TML-001 | Clasificaci√≥n de hoja sana | PlantVillage | Clase "Healthy" con ‚â•90% confianza |
| TML-002 | Detecci√≥n de mildiu | PlantVillage | Clase correcta con ‚â•85% confianza |
| TML-003 | Imagen borrosa/oscura | Sint√©tico | Confianza baja (<60%) o rechazo |
| TML-004 | Imagen sin planta | Sint√©tico | Rechazo o "Unknown" |
| TML-005 | Batch de 10 im√°genes | PlantVillage | Consistencia en clasificaci√≥n |

#### **Pruebas de Sesgo del Modelo**
- Validar performance equitativa entre especies de plantas
- Verificar resultados con diferentes condiciones de iluminaci√≥n
- Probar con im√°genes de diferentes fuentes (no solo PlantVillage)

---

### 3.6 Pruebas de Usabilidad

#### **Criterios de Evaluaci√≥n**
| Criterio | M√©todo | Meta |
|----------|--------|------|
| Facilidad de aprendizaje | Time-to-first-task | < 5 minutos |
| Eficiencia | Task completion time | < 2 min para tareas comunes |
| Tasa de error | Error rate | < 5% |
| Satisfacci√≥n | SUS Score | ‚â• 70 |
| Accesibilidad | WCAG 2.1 AA | 100% cumplimiento |

#### **Tareas de Usuario**
1. Registrar un nuevo cultivo
2. Capturar y analizar imagen de planta
3. Ver lecturas de sensores en tiempo real
4. Responder a una alerta
5. Consultar recomendaciones hist√≥ricas

---

### 3.7 Pruebas de Instalaci√≥n/Despliegue

| ID | Escenario | Plataforma | Criterio de √âxito |
|----|-----------|------------|-------------------|
| TD-001 | Instalaci√≥n limpia | Windows 10/11 | Sin errores, todos los servicios arriba |
| TD-002 | Instalaci√≥n limpia | Ubuntu 20.04/22.04 | Sin errores, todos los servicios arriba |
| TD-003 | Instalaci√≥n limpia | macOS 12+ | Sin errores, todos los servicios arriba |
| TD-004 | Actualizaci√≥n de versi√≥n | Todas | Datos preservados, sin downtime |
| TD-005 | Configuraci√≥n de .env | Todas | Variables requeridas documentadas |
| TD-006 | Conexi√≥n a MongoDB | Todas | Atlas + Local funcionan |
| TD-007 | Carga de modelos TF.js | Todas | Modelos se sirven correctamente |

---

## 4. Gesti√≥n de Datos de Prueba

### 4.1 Datos de Prueba Requeridos

#### **Usuarios**
- 5 usuarios de prueba con diferentes roles
- Credenciales v√°lidas e inv√°lidas
- Usuarios con/sin cultivos asignados

#### **Cultivos**
- 10 cultivos de diferentes tipos (tomate, lechuga, ma√≠z, etc.)
- Estados: activos, cosechados, en alerta
- Con/sin datos de sensores asociados

#### **Sensores**
- Lecturas simuladas en rangos normales
- Lecturas con valores l√≠mite
- Lecturas con valores inv√°lidos

#### **Im√°genes de Plantas**
- 50 im√°genes del dataset PlantVillage
- 20 im√°genes de calidad variable (borrosas, oscuras)
- 10 im√°genes no v√°lidas (sin plantas, corruptas)

### 4.2 Gesti√≥n de Ambientes

| Ambiente | Prop√≥sito | Datos | Acceso |
|----------|-----------|-------|--------|
| Desarrollo (DEV) | Desarrollo diario | Mock/Sint√©tico | Desarrolladores |
| Pruebas (QA) | Testing funcional | Sint√©tico + Dataset | QA + Dev |
| Staging (STG) | Pre-producci√≥n | Copia de PROD | QA + PO |
| Producci√≥n (PROD) | Usuarios finales | Real | Usuarios |

---

## 5. Criterios de Entrada y Salida

### 5.1 Criterios de Entrada
- [ ] C√≥digo completo para la funcionalidad
- [ ] Revisi√≥n de c√≥digo aprobada
- [ ] Documentaci√≥n t√©cnica actualizada
- [ ] Datos de prueba preparados
- [ ] Ambiente de pruebas disponible
- [ ] Build exitoso sin errores de compilaci√≥n

### 5.2 Criterios de Salida
- [ ] Ejecuci√≥n de todos los casos de prueba planificados
- [ ] ‚â• 95% de casos cr√≠ticos PASS
- [ ] ‚â• 90% de casos alta prioridad PASS
- [ ] 0 defectos cr√≠ticos abiertos
- [ ] ‚â§ 3 defectos alta prioridad abiertos (con plan de remediaci√≥n)
- [ ] Pruebas de seguridad ‚â• 80% PASS
- [ ] M√©tricas de rendimiento dentro de objetivos
- [ ] Documentaci√≥n de defectos completa

---

## 6. Gesti√≥n de Defectos

### 6.1 Clasificaci√≥n de Severidad

| Nivel | Descripci√≥n | Ejemplo | SLA |
|-------|-------------|---------|-----|
| **Cr√≠tico** | Sistema no funciona, p√©rdida de datos | DB down, IA no responde | 4 horas |
| **Alto** | Funcionalidad principal afectada | No se pueden crear cultivos | 24 horas |
| **Medio** | Funcionalidad secundaria afectada | Filtro de b√∫squeda no funciona | 3 d√≠as |
| **Bajo** | Problema cosm√©tico, UX menor | Alineaci√≥n de texto | 1 semana |

### 6.2 Proceso de Reporte
1. Documentar en sistema de tracking (GitHub Issues / Jira)
2. Incluir: pasos de reproducci√≥n, evidencia (screenshots/logs), ambiente
3. Asignar severidad y prioridad
4. Notificar a equipo de desarrollo
5. Seguimiento hasta resoluci√≥n
6. Verificaci√≥n de fix en ambiente QA

### 6.3 M√©tricas de Defectos
- **Defect Density:** Defectos / KLOC
- **Defect Removal Efficiency:** (Defectos encontrados pre-release) / (Total defectos)
- **Defect Leakage:** Defectos encontrados en PROD
- **Mean Time to Resolve (MTTR):** Tiempo promedio de resoluci√≥n

---

## 7. Recursos Necesarios

### 7.1 Equipo
| Rol | Cantidad | Responsabilidad |
|-----|----------|-----------------|
| QA Lead | 1 | Planificaci√≥n, coordinaci√≥n, reporte |
| QA Engineer | 2 | Ejecuci√≥n de pruebas, automatizaci√≥n |
| Desarrollador (soporte) | 2 | Fixes, soporte t√©cnico |
| Product Owner | 1 | Validaci√≥n de aceptaci√≥n |

### 7.2 Infraestructura
- Servidor de pruebas (4 cores, 8GB RAM)
- Base de datos MongoDB de pruebas
- Navegadores: Chrome, Firefox, Safari, Edge (√∫ltimas 2 versiones)
- Dispositivos m√≥viles f√≠sicos (iOS, Android)
- Herramientas de pruebas de carga (JMeter, k6)

### 7.3 Herramientas

| Categor√≠a | Herramienta | Prop√≥sito |
|-----------|-------------|-----------|
| Testing Framework | Jest, Mocha, PyTest | Pruebas unitarias |
| E2E Testing | Cypress, Playwright | Pruebas end-to-end |
| API Testing | Supertest, Postman | Pruebas de API |
| Security Testing | OWASP ZAP, Burp Suite | Pruebas de seguridad |
| Performance | JMeter, k6 | Carga y rendimiento |
| Tracking | GitHub Issues, Jira | Gesti√≥n de defectos |
| CI/CD | GitHub Actions | Automatizaci√≥n |

---

## 8. Cronograma

### 8.1 Fases del Proyecto

| Fase | Duraci√≥n | Actividades Principales |
|------|----------|-------------------------|
| **Preparaci√≥n** | Semana 1 | Setup ambientes, datos de prueba, scripts |
| **Pruebas Unitarias** | Continuo | Ejecuci√≥n autom√°tica en cada commit |
| **Pruebas de Integraci√≥n** | Semanas 2-3 | API endpoints, flujos backend |
| **Pruebas de Sistema** | Semanas 3-4 | End-to-end, cross-browser |
| **Pruebas de Seguridad** | Semana 4 | Escaneo automatizado + manual |
| **Pruebas de Rendimiento** | Semana 5 | Carga, estr√©s, estabilidad |
| **Pruebas de Aceptaci√≥n** | Semana 6 | Validaci√≥n con usuarios |
| **Regresi√≥n Final** | Semana 7 | Suite completa pre-release |

### 8.2 Hitos
- **Semana 2:** Pruebas de humo completas (Smoke Test Suite)
- **Semana 4:** Todas las pruebas funcionales cr√≠ticas PASS
- **Semana 5:** Seguridad validada (‚â•80% PASS)
- **Semana 6:** Rendimiento validado
- **Semana 7:** Go/No-Go para producci√≥n

---

## 9. Riesgos y Mitigaci√≥n

| Riesgo | Probabilidad | Impacto | Estrategia de Mitigaci√≥n |
|--------|--------------|---------|--------------------------|
| API externa (clima) no disponible | Media | Alto | Implementar fallback con datos mock |
| Modelo de IA con baja precisi√≥n | Baja | Cr√≠tico | Re-entrenamiento con m√°s datos, ajuste hiperpar√°metros |
| Datos de sensores inconsistentes | Alta | Medio | Validaci√≥n estricta en backend, alertas |
| Rate limiting muy estricto | Media | Medio | Configuraci√≥n ajustable por ambiente |
| MongoDB Atlas con latencia alta | Baja | Alto | Conexi√≥n local para testing, optimizaci√≥n de queries |
| Equipo QA insuficiente | Media | Alto | Automatizaci√≥n agresiva, priorizaci√≥n |

---

## 10. Entregables

### 10.1 Documentos
- [x] Plan de Pruebas (este documento)
- [ ] Casos de Prueba detallados (Test Cases)
- [ ] Scripts de prueba automatizados
- [ ] Reporte de ejecuci√≥n de pruebas
- [ ] Reporte de defectos
- [ ] Matriz de trazabilidad (Requisitos ‚Üî Casos de Prueba)

### 10.2 Artefactos
- [ ] Suite de pruebas automatizadas (Jest, Cypress)
- [ ] Scripts de seguridad (`test-security.ps1`, `test-security.sh`)
- [ ] Scripts de carga (JMeter/k6)
- [ ] Dataset de pruebas (im√°genes, datos de sensores)
- [ ] Configuraciones de ambientes (.env templates)

---

## 11. M√©tricas y KPIs

### 11.1 Cobertura de Pruebas
- **Code Coverage:** ‚â• 70%
- **Requirement Coverage:** 100% (requisitos cr√≠ticos)
- **Risk Coverage:** 100% (riesgos altos y cr√≠ticos)

### 11.2 Calidad
- **Pass Rate:** ‚â• 95% (casos cr√≠ticos)
- **Defect Density:** ‚â§ 5 defectos por KLOC
- **Defect Leakage:** ‚â§ 2% (defectos en producci√≥n)

### 11.3 Eficiencia
- **Test Execution Time:** ‚â§ 2 horas (suite completa)
- **Automation Rate:** ‚â• 60% de casos automatizados
- **MTTR (Mean Time to Resolve):** ‚â§ 24h (cr√≠ticos), ‚â§ 3 d√≠as (altos)

### 11.4 Rendimiento
- **API Response Time (p95):** ‚â§ 200ms
- **IA Inference Time:** ‚â§ 2s
- **Throughput:** ‚â• 100 req/s (lecturas de sensores)
- **Error Rate:** ‚â§ 0.1%

---

## 12. Aprobaciones

| Rol | Nombre | Firma | Fecha |
|-----|--------|-------|-------|
| QA Lead | | | |
| Project Manager | | | |
| Tech Lead | | | |
| Product Owner | | | |

---

## 13. Referencias

### 13.1 Documentos Relacionados
- `SECURITY_FIXES.md` - Hardening de seguridad implementado
- `TESTING_SECURITY.md` - Gu√≠a de ejecuci√≥n de pruebas de seguridad
- `README.md` - Documentaci√≥n general del proyecto
- `docs/IA_TRAINING.md` - Entrenamiento del modelo de IA

### 13.2 Est√°ndares y Gu√≠as
- OWASP Top 10 (2021)
- WCAG 2.1 Level AA
- ISO/IEC 25010 (Software Quality Model)
- IEEE 829 (Software Test Documentation)

### 13.3 Herramientas y Scripts
- `test-security.ps1` / `test-security.sh` - Script de pruebas de seguridad automatizadas
- `package.json` - Configuraci√≥n de scripts de prueba
- `.env.example` - Template de configuraci√≥n

---

## 14. Historial de Cambios

| Versi√≥n | Fecha | Autor | Cambios |
|---------|-------|-------|---------|
| 1.0 | Nov 2025 | Equipo AgroSens | Creaci√≥n inicial del plan |

---

## 15. Anexos

### Anexo A: Checklist de Preparaci√≥n de Ambiente
```bash
# Backend
cd backend
npm install
cp .env.example .env
# Configurar MONGO_URI, SESSION_SECRET, CSRF_SECRET
npm start

# Frontend
cd frontend
npm install
npm run dev

# Verificar conectividad
curl http://localhost:5000/health
curl http://localhost:3000

# Ejecutar pruebas de seguridad
.\test-security.ps1
```

### Anexo B: Template de Caso de Prueba
```markdown
**ID:** TC-XXX
**T√≠tulo:** [Nombre descriptivo]
**M√≥dulo:** [Backend/Frontend/IA]
**Prioridad:** [Cr√≠tica/Alta/Media/Baja]
**Precondiciones:** 
- [Listar precondiciones]

**Pasos:**
1. [Paso 1]
2. [Paso 2]
3. [Paso 3]

**Resultado Esperado:**
[Descripci√≥n del resultado esperado]

**Datos de Prueba:**
- Input: [datos]
- Output esperado: [datos]

**Ambiente:** [DEV/QA/STG]
**Estado:** [Pendiente/En progreso/PASS/FAIL]
**Ejecutado por:** [Nombre]
**Fecha:** [DD/MM/YYYY]
**Evidencia:** [Link a screenshot/log]
```

### Anexo C: Comando R√°pidos

#### Ejecutar pruebas unitarias
```bash
# Backend
npm test

# Frontend
npm test

# Python (ML)
pytest backend/ml/
```

#### Ejecutar pruebas de seguridad
```powershell
# Windows
.\test-security.ps1

# Linux/Mac
bash test-security.sh
```

#### Ejecutar suite E2E
```bash
cd frontend
npx cypress open
# o headless
npx cypress run
```

#### Generar reporte de cobertura
```bash
npm test -- --coverage
```

---

**Fin del Documento**
